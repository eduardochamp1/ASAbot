import streamlit as st
import google.generativeai as genai
import time
import random

# --- CONFIGURA√á√ÉO DA P√ÅGINA ---
st.set_page_config(
    page_title="A.S.A. Interface",
    page_icon="ü§ñ",
    layout="wide"
)

# --- GERENCIAMENTO DE ESTADO (MEM√ìRIA) ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- BARRA LATERAL (SIDEBAR) ---
with st.sidebar:
    st.header("Configura√ß√µes A.S.A.")
    
    # Input da API Key
    api_key = st.text_input("Gemini API Key", type="password", help="Cole sua chave da API do Google Gemini aqui.")
    
    if api_key:
        genai.configure(api_key=api_key)
    
    st.divider()

    # Bot√£o para limpar hist√≥rico
    if st.button("Limpar Hist√≥rico"):
        st.session_state.messages = []
        st.rerun()
        
    st.divider()
    
    # Configura√ß√£o de Criatividade
    criatividade = st.slider(
        "N√≠vel de Criatividade", 
        min_value=0.0, 
        max_value=1.0, 
        value=0.7, 
        step=0.1
    )
    st.caption(f"Criatividade atual: {criatividade}")
    
    st.divider()
    st.markdown("### Sobre")
    st.markdown("Interface Web do Agente **A.S.A.**")

# --- FUN√á√ÉO BACKEND (GEMINI) ---
def processar_comando_asa(prompt, history):
    """
    Processa o comando usando a API do Google Gemini.
    """
    if not api_key:
        return "‚ö†Ô∏è Por favor, insira sua **Gemini API Key** na barra lateral para eu funcionar."

    try:
        # Configura√ß√£o do Modelo
        generation_config = {
            "temperature": criatividade,
            "top_p": 0.95,
            "top_k": 64,
            "max_output_tokens": 8192,
        }
        
        # Instru√ß√µes de Sistema (Persona)
        system_instruction = "Voc√™ √© o A.S.A. (Agente de Suporte e Assist√™ncia). Voc√™ √© um assistente virtual inteligente, prestativo e ligeiramente ir√¥nico. Responda de forma concisa e direta, mas com personalidade. Se o usu√°rio falar portugu√™s, responda em portugu√™s."

        model = genai.GenerativeModel(
            model_name="gemini-1.5-flash",
            generation_config=generation_config,
            system_instruction=system_instruction
        )
        
        # Converte hist√≥rico do Streamlit para o formato do Gemini
        chat = model.start_chat(history=[
            {"role": "user" if m["role"] == "user" else "model", "parts": [m["content"]]}
            for m in history
        ])
        
        # Envia a mensagem
        response = chat.send_message(prompt)
        return response.text

    except Exception as e:
        return f"‚ùå Erro ao processar: {str(e)}"

# --- INTERFACE PRINCIPAL ---
st.title("ü§ñ A.S.A. Interface")

if not api_key:
    st.warning("üëà Para come√ßar, cole sua **Gemini API Key** na barra lateral.")
    st.info("N√£o tem uma chave? Crie gr√°tis aqui: [Google AI Studio](https://aistudio.google.com/app/apikey)")

# Exibir hist√≥rico de mensagens
for message in st.session_state.messages:
    avatar = "üë§" if message["role"] == "user" else "ü§ñ"
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"])

# Captura de entrada do usu√°rio
if prompt := st.chat_input("Digite seu comando para o A.S.A...."):
    # 1. Adicionar mensagem do usu√°rio ao hist√≥rico visual
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="üë§"):
        st.markdown(prompt)

    # 2. Processar resposta (Backend Real)
    with st.chat_message("assistant", avatar="ü§ñ"):
        with st.spinner("A.S.A. est√° pensando..."):
            # Passa o hist√≥rico (excluindo a √∫ltima msg que acabamos de adicionar para evitar duplica√ß√£o no envio se n√£o tratada, mas a lib lida bem, aqui passamos o anterior)
            resposta = processar_comando_asa(prompt, st.session_state.messages[:-1])
            st.markdown(resposta)
    
    # 3. Adicionar resposta do agente ao hist√≥rico
    st.session_state.messages.append({"role": "assistant", "content": resposta})
